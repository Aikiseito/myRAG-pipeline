{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community langchain-mistralai ollama faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLjrpZuLSFkc",
        "outputId": "9bd54ce1-8791-4a0a-8eab-685b28632101"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain-mistralai in /usr/local/lib/python3.11/dist-packages (0.2.4)\n",
            "Requirement already satisfied: ollama in /usr/local/lib/python3.11/dist-packages (0.4.6)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.29)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (2.10.5)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.21.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai) (0.14.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-mistralai) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain-mistralai) (0.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.67.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistral_api_key = # PUT HERE YOUR API KEY"
      ],
      "metadata": {
        "id": "-F2aC7ggDNbf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cpSRcsHrEPYr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Optional, List, Tuple\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings, OllamaEmbeddings, OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import Ollama, VLLM, HuggingFaceHub, OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "import glob\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "import numpy as np\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import EmbeddingsFilter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(directory):\n",
        "    \"\"\"\n",
        "    Загружаем текстовые документы из файлов\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    for file_path in glob.glob(os.path.join(directory, \"lecture*.txt\")):\n",
        "        try:\n",
        "            loader = TextLoader(file_path, encoding=\"utf-8\")\n",
        "            documents.extend(loader.load())\n",
        "            print(file_path, end=' ')\n",
        "        except Exception as e:\n",
        "            print(f\"Не удалось загрузить файл {file_path}: {e}\")\n",
        "    return documents\n",
        "\n",
        "data_directory = \"./data\"\n",
        "documents = load_documents(data_directory)"
      ],
      "metadata": {
        "id": "_cgeQdEdR6y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c734f164-2bd9-4ec1-98f6-18ebed25ef6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/lecture1.txt ./data/lecture8.txt ./data/lecture2.txt ./data/lecture9.txt ./data/lecture10.txt ./data/lecture14.txt ./data/lecture11.txt ./data/lecture13.txt ./data/lecture5.txt ./data/lecture7.txt ./data/lecture6.txt ./data/lecture4.txt ./data/lecture12.txt ./data/lecture3.txt "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MARKDOWN_SEPARATORS = [\n",
        "    \"\\subsection\",\n",
        "    \"\\begin{exframe}\",\n",
        "    \"\\end{exframe}\"\n",
        "    \"\\n#{1,6} \",\n",
        "    \"```\\n\",\n",
        "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
        "    \"\\n---+\\n\",\n",
        "    \"\\n___+\\n\",\n",
        "    \"\\n\\n\",\n",
        "    \"\\n\",\n",
        "    \" \",\n",
        "    \"\",\n",
        "]\n",
        "\n",
        "def split_text(documents, chunk_size=2000, chunk_overlap=200):\n",
        "    \"\"\"\n",
        "    Разбиваем текст на чанки с заданными размером и перекрытием.\n",
        "    Используем RecursiveCharacterTextSplitter, поскольку он разбивает\n",
        "    текст, учитывая знаки препинания и структуру текста\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "        add_start_index=True,\n",
        "        strip_whitespace=True,\n",
        "        separators=MARKDOWN_SEPARATORS,\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    return chunks\n",
        "\n",
        "chunks = split_text(documents)"
      ],
      "metadata": {
        "id": "yw8qtoFJTits"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embeddings(chunks, embedding_type=\"huggingface\", model_name=\"all-MiniLM-L6-v2\"):\n",
        "    \"\"\"\n",
        "    Создаём эмбеддинги для текстовых чанков\n",
        "    \"\"\"\n",
        "    if embedding_type == \"huggingface\":\n",
        "        embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "    elif embedding_type == \"ollama\":\n",
        "        embeddings = OllamaEmbeddings(model=\"llama3\")\n",
        "    elif embedding_type == \"openai\":\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n",
        "\n",
        "    db = FAISS.from_documents(chunks, embeddings)\n",
        "    return db\n",
        "\n",
        "db = create_embeddings(chunks, embedding_type=\"huggingface\", model_name=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "RhmSG7KfUYpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227ff577-bf31-448b-beaa-fc3a4679d282"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-34b54ddd729d>:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rag_chain(db, model_name=\"mistral-large-latest\"):\n",
        "    \"\"\"\n",
        "    Создаём RAG-цепочку для получения ответов на вопросы пользователя\n",
        "    \"\"\"\n",
        "    llm = ChatMistralAI(mistral_api_key=mistral_api_key, model=model_name, timeout=50)\n",
        "\n",
        "    template = \"\"\"\n",
        "    Тебе даны текст и вопрос (смотри ниже). Нужно ответить на вопрос используя только информацию из предоставленного\n",
        "    текста. При этом ты должен создать ощущение, что ты понимаешь, о чём этот текст.\n",
        "    Ответ должен сохранять смысл, который был в тексте, при этом можно перефразировать предложения.\n",
        "    Ничего добавлять от себя нельзя.\n",
        "    Если в полученном тексте нет ответа, скажи, что ответа нет, не пытайся создать ответ самостоятельно.\n",
        "\n",
        "    Текст: {context}\n",
        "\n",
        "    Вопрос: {question}\n",
        "    Ответ:\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                          chain_type=\"stuff\",\n",
        "                                          retriever=db.as_retriever(search_kwargs={\"k\": 5}),\n",
        "                                          chain_type_kwargs={\"prompt\": prompt})\n",
        "    return qa_chain\n",
        "\n",
        "\n",
        "rag_chain = create_rag_chain(db, model_name='mistral-large-2402')\n",
        "\n",
        "\n",
        "#def get_response(query):\n",
        "#  response = rag_chain.run(query)\n",
        "#  return response"
      ],
      "metadata": {
        "id": "obGuOoLpVFAW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(query, num_responses=3):\n",
        "    \"\"\"\n",
        "    Генерируем несколько ответов на запрос и выбираем лучший\n",
        "    с помощью функции choose_best_response\n",
        "    \"\"\"\n",
        "    responses = []\n",
        "    for _ in range(num_responses):\n",
        "        responses.append(rag_chain.run(query))\n",
        "    return choose_best_response(responses)\n",
        "\n",
        "def choose_best_response(responses: List[str]) -> str:\n",
        "    \"\"\"\n",
        "        Выбираем лучший ответ из списка\n",
        "        Лучший = с наивысшей оценкой (произведение длины ответа и уникальности токенов)\n",
        "    \"\"\"\n",
        "    if not responses:\n",
        "        return \"Нет ответов\"\n",
        "\n",
        "    def score_response(response):\n",
        "        tokens = response.split()\n",
        "        unique_tokens = set(tokens)\n",
        "        return len(tokens) * len(unique_tokens)\n",
        "\n",
        "    scores = [score_response(response) for response in responses]\n",
        "    best_index = np.argmax(scores)\n",
        "    return responses[best_index]\n"
      ],
      "metadata": {
        "id": "s2v5tHWkQ3lX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Очень кратко расскажи, какие главные понятия содержит этот документ\"\n",
        "response = get_response(user_query)\n",
        "print(f\"Question: {user_query}\")\n",
        "print(f\"Answer: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SVV6jieVE4l",
        "outputId": "a842d3ca-96bf-4b0b-afa9-cf5a1d593a8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-576e4a070440>:8: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  responses.append(rag_chain.run(query))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Очень кратко расскажи, какие главные понятия содержит этот документ\n",
            "Answer: Главные понятия, содержащиеся в этом документе, включают:\n",
            "\n",
            "1. Оптимизацию на \"простых\" множествах, проекцию и метод Франк-Вульфа.\n",
            "2. Централизованный спуск и проблему коммуникационного узкого места в распределенном обучении.\n",
            "3. Методы борьбы за эффективные коммуникации.\n",
            "4. Одновременные и поочередные обновления переменных.\n",
            "5. Метод поочередного градиентного спуска-подъема (Alt-GDA) и его алгоритм.\n",
            "6. Проблемы сходимости методов градиентного спуска-подъема в не сильно выпуклых-сильно вогнутых задачах.\n",
            "7. Метод внутренней точки как альтернативу методу барьеров.\n",
            "\n",
            "Эти понятия относятся к области оптимизации и машинного обучения.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Что такое градиентный спуск?\"\n",
        "response = get_response(user_query)\n",
        "print(f\"Question: {user_query}\")\n",
        "print(f\"Answer: {response}\")\n",
        "\n",
        "user_query = \"Есть ли другие документы на эту же тему?\"\n",
        "response = get_response(user_query)\n",
        "print(f\"Question: {user_query}\")\n",
        "print(f\"Answer: {response}\")"
      ],
      "metadata": {
        "id": "vrT79UmLSBFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b27fe4c-a186-4823-cf02-471349a9b9b9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Что такое градиентный спуск?\n",
            "Answer: Градиентный спуск - это метод оптимизации, используемый для минимизации функции. Суть метода заключается в последовательном вычислении градиента функции в текущей точке и переходе в новую точку, которая выбирается в направлении противоположном градиенту. Целью является нахождение такой точки, в которой функция принимает минимальное значение. В тексте также упоминается вопрос о сходимости этого метода и о допустимых диапазонах шагов.\n",
            "Question: Есть ли другие документы на эту же тему?\n",
            "Answer: Из предоставленного текста невозможно узнать, есть ли другие документы на эту же тему. Текст содержит информацию о лекции, посвященной седловой задаче, методу экстраградиента, прямо-двойственному методу, градиентному спуску для гладких сильно выпуклых задач, барьерным функциям и другим связанным темам, но не содержит ссылок на другие документы.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Простой Telegram Bot**"
      ],
      "metadata": {
        "id": "5u3gP_v7ggVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade python-telegram-bot telebot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBy-OkPkgfb9",
        "outputId": "8320daeb-1070-4659-d1b4-6f6ab0d13a78"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.11/dist-packages (21.10)\n",
            "Requirement already satisfied: telebot in /usr/local/lib/python3.11/dist-packages (0.0.5)\n",
            "Requirement already satisfied: httpx~=0.27 in /usr/local/lib/python3.11/dist-packages (from python-telegram-bot) (0.27.2)\n",
            "Requirement already satisfied: pyTelegramBotAPI in /usr/local/lib/python3.11/dist-packages (from telebot) (4.26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from telebot) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx~=0.27->python-telegram-bot) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->telebot) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->telebot) (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MY_TOKEN = # PUT HERE YOUR TELEGRAM BOT TOKEN\n",
        "\n",
        "import telebot\n",
        "import random\n",
        "\n",
        "bot = telebot.TeleBot(MY_TOKEN)\n",
        "\n",
        "@bot.message_handler(commands = ['start'])\n",
        "def start(message):\n",
        "  bot.send_message(message.chat.id, \"Привет! Я бот, готовый ответить на твои вопросы по курсу Методы оптимизации МФТИ. Задай свой вопрос\")\n",
        "\n",
        "@bot.message_handler(func=lambda message: True)\n",
        "def handle_message(message):\n",
        "  random_messages = ['Ну и вопрос! Подожди, пожалуйста, я подумаю', 'Подожди, где-то я уже такое видел... Проверяю', 'Дай подумать, минуточку',\n",
        "                     'Хмм...', 'Сейчас-сейчас...', 'Надо подумать', 'О, это я знаю. Наверно :)', 'Сейчас я тебя впечатлю, подожди минуточку',\n",
        "                     'Дай мне минутку, я обрабатываю твой вопрос', 'Кручу шестеренки...', 'Загрузка...', 'Соображаю...', 'Копаюсь в книге знаний',\n",
        "                     'Консультируюсь с гением внутри меня', 'Перевариваю информацию...', 'Щелкаю пальцами в раздумьях', 'Подключаюсь к главному компьютеру...',\n",
        "                     'Погружаюсь в глубины знаний...', 'Поджигаю свои нейроны', 'Катаюсь на ментальных американских горках', 'Пишу код, который тебе понравится',\n",
        "                     'Вычисляю ответ с помощью супербыстрого мозга', 'Болтаю с другими ботами, чтобы получить идеи', 'Беру паузу, чтобы сварить себе чашечку кофе',\n",
        "                     'Провожу тестирование на горячо любимых хомячках', 'Выполняю сложные алгоритмы...', 'Пытаюсь понять, что ты все-таки имеешь в виду...']\n",
        "  send_thinking = random.choice(random_messages)\n",
        "  bot.send_message(message.chat.id, send_thinking)\n",
        "  try:\n",
        "      response = get_response(message.text)\n",
        "  except:\n",
        "      bot.send_message(message.chat.id, \"Мы превысили лимит токенов в минуту, подожди немного и повтори вопрос\")\n",
        "  bot.reply_to(message, 'Вот ответ на твой вопрос: \\n' + response)\n",
        "\n",
        "bot.polling()"
      ],
      "metadata": {
        "id": "WNXoHymqmDyT"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}